{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing Tools**\n",
    "## Machine Learning\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/68/LOGO_UEU_BY_ASU-06.png\" width=50% height=50%>\n",
    "\n",
    "<table style=\"width:75%\">\n",
    "  <tr>\n",
    "    <td><b>Dosen Pengampu</b></td>\n",
    "    <td>Jefry Sunupurwa Asri , S.Kom., M.Kom.</td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td><b>Mahasiswa</b></td>\n",
    "    <td>Andika Noor Ismawan</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NIM</b></td>\n",
    "    <td>20210801465</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Pertemuan3/Employee_Data_Company.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "z = dataset.iloc[[2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   EmployeeID   20 non-null     int64  \n",
      " 1   FirstName    20 non-null     object \n",
      " 2   LastName     20 non-null     object \n",
      " 3   Email        20 non-null     object \n",
      " 4   Department   20 non-null     object \n",
      " 5   Title        20 non-null     object \n",
      " 6   Salary       16 non-null     float64\n",
      " 7   JoiningDate  20 non-null     object \n",
      " 8   Active       20 non-null     bool   \n",
      "dtypes: bool(1), float64(1), int64(1), object(6)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeID     0\n",
       "FirstName      0\n",
       "LastName       0\n",
       "Email          0\n",
       "Department     0\n",
       "Title          0\n",
       "Salary         4\n",
       "JoiningDate    0\n",
       "Active         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103 'Michael' 'Johnson' 'michaeljohnson@example.com' 'IT'\n",
      "  'Software Engineer' nan '2021-01-10' True]]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101 'John' 'Doe' 'johndoe@example.com' 'HR' 'HR Manager' 60000.0\n",
      "  '2020-03-15']\n",
      " [102 'Jane' 'Smith' 'janesmith@example.com' 'Finance' 'Accountant'\n",
      "  50000.0 '2019-07-20']\n",
      " [103 'Michael' 'Johnson' 'michaeljohnson@example.com' 'IT'\n",
      "  'Software Engineer' nan '2021-01-10']\n",
      " [104 'Emily' 'Williams' 'emilywilliams@example.com' 'Marketing'\n",
      "  'Marketing Manager' 65000.0 '2018-11-05']\n",
      " [105 'David' 'Brown' 'davidbrown@example.com' 'Sales'\n",
      "  'Sales Representative' 55000.0 '2020-09-30']\n",
      " [106 'Lisa' 'Miller' 'lisamiller@example.com' 'HR' 'HR Specialist' nan\n",
      "  '2019-02-12']\n",
      " [107 'Robert' 'Anderson' 'robertanderson@example.com' 'Finance'\n",
      "  'Financial Analyst' 55000.0 '2020-06-25']\n",
      " [108 'Susan' 'Clark' 'susanclark@example.com' 'IT'\n",
      "  'Database Administrator' 68000.0 '2019-04-08']\n",
      " [109 'Matthew' 'White' 'matthewwhite@example.com' 'Marketing'\n",
      "  'Marketing Coordinator' 48000.0 '2021-03-20']\n",
      " [110 'Laura' 'Taylor' 'laurataylor@example.com' 'Sales' 'Sales Manager'\n",
      "  75000.0 '2018-08-14']\n",
      " [111 'James' 'Kennedy' 'jameskennedy@example.com' 'HR' 'HR Assistant'\n",
      "  42000.0 '2022-02-05']\n",
      " [112 'Elizabeth' 'Hall' 'elizabethhall@example.com' 'Finance'\n",
      "  'Senior Accountant' 60000.0 '2017-12-18']\n",
      " [113 'William' 'Wilson' 'williamwilson@example.com' 'IT'\n",
      "  'Software Developer' 72000.0 '2020-11-30']\n",
      " [114 'Amy' 'Adams' 'amyadams@example.com' 'Marketing'\n",
      "  'Marketing Specialist' 52000.0 '2019-09-09']\n",
      " [115 'Charles' 'Thomas' 'charlesthomas@example.com' 'Sales'\n",
      "  'Sales Associate' 48000.0 '2021-06-28']\n",
      " [116 'Mary' 'Turner' 'maryturner@example.com' 'HR' 'Recruiter' 48000.0\n",
      "  '2022-03-10']\n",
      " [117 'George' 'Baker' 'georgebaker@example.com' 'Finance'\n",
      "  'Junior Accountant' 42000.0 '2018-04-15']\n",
      " [118 'Anna' 'Garcia' 'annagarcia@example.com' 'IT'\n",
      "  'Network Administrator' nan '2017-10-22']\n",
      " [119 'Joseph' 'Evans' 'josephevans@example.com' 'Marketing'\n",
      "  'Content Writer' 46000.0 '2020-08-03']\n",
      " [120 'Sophia' 'Harris' 'sophiaharris@example.com' 'Sales'\n",
      "  'Sales Coordinator' nan '2019-01-17']]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 6:7])\n",
    "X[:, 6:7] = imputer.transform(X[:, 6:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101 'John' 'Doe' 'johndoe@example.com' 'HR' 'HR Manager' 60000.0\n",
      "  '2020-03-15']\n",
      " [102 'Jane' 'Smith' 'janesmith@example.com' 'Finance' 'Accountant'\n",
      "  50000.0 '2019-07-20']\n",
      " [103 'Michael' 'Johnson' 'michaeljohnson@example.com' 'IT'\n",
      "  'Software Engineer' 55375.0 '2021-01-10']\n",
      " [104 'Emily' 'Williams' 'emilywilliams@example.com' 'Marketing'\n",
      "  'Marketing Manager' 65000.0 '2018-11-05']\n",
      " [105 'David' 'Brown' 'davidbrown@example.com' 'Sales'\n",
      "  'Sales Representative' 55000.0 '2020-09-30']\n",
      " [106 'Lisa' 'Miller' 'lisamiller@example.com' 'HR' 'HR Specialist'\n",
      "  55375.0 '2019-02-12']\n",
      " [107 'Robert' 'Anderson' 'robertanderson@example.com' 'Finance'\n",
      "  'Financial Analyst' 55000.0 '2020-06-25']\n",
      " [108 'Susan' 'Clark' 'susanclark@example.com' 'IT'\n",
      "  'Database Administrator' 68000.0 '2019-04-08']\n",
      " [109 'Matthew' 'White' 'matthewwhite@example.com' 'Marketing'\n",
      "  'Marketing Coordinator' 48000.0 '2021-03-20']\n",
      " [110 'Laura' 'Taylor' 'laurataylor@example.com' 'Sales' 'Sales Manager'\n",
      "  75000.0 '2018-08-14']\n",
      " [111 'James' 'Kennedy' 'jameskennedy@example.com' 'HR' 'HR Assistant'\n",
      "  42000.0 '2022-02-05']\n",
      " [112 'Elizabeth' 'Hall' 'elizabethhall@example.com' 'Finance'\n",
      "  'Senior Accountant' 60000.0 '2017-12-18']\n",
      " [113 'William' 'Wilson' 'williamwilson@example.com' 'IT'\n",
      "  'Software Developer' 72000.0 '2020-11-30']\n",
      " [114 'Amy' 'Adams' 'amyadams@example.com' 'Marketing'\n",
      "  'Marketing Specialist' 52000.0 '2019-09-09']\n",
      " [115 'Charles' 'Thomas' 'charlesthomas@example.com' 'Sales'\n",
      "  'Sales Associate' 48000.0 '2021-06-28']\n",
      " [116 'Mary' 'Turner' 'maryturner@example.com' 'HR' 'Recruiter' 48000.0\n",
      "  '2022-03-10']\n",
      " [117 'George' 'Baker' 'georgebaker@example.com' 'Finance'\n",
      "  'Junior Accountant' 42000.0 '2018-04-15']\n",
      " [118 'Anna' 'Garcia' 'annagarcia@example.com' 'IT'\n",
      "  'Network Administrator' 55375.0 '2017-10-22']\n",
      " [119 'Joseph' 'Evans' 'josephevans@example.com' 'Marketing'\n",
      "  'Content Writer' 46000.0 '2020-08-03']\n",
      " [120 'Sophia' 'Harris' 'sophiaharris@example.com' 'Sales'\n",
      "  'Sales Coordinator' 55375.0 '2019-01-17']]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Data\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For a sparse output, all columns should be a numeric or convertible to a numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py:857\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[0;34m(self, Xs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# dtype conversion if necessary.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m     converted_Xs \u001b[39m=\u001b[39m [\n\u001b[1;32m    858\u001b[0m         check_array(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    859\u001b[0m         \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m Xs\n\u001b[1;32m    860\u001b[0m     ]\n\u001b[1;32m    861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py:858\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# dtype conversion if necessary.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     converted_Xs \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 858\u001b[0m         check_array(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    859\u001b[0m         \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m Xs\n\u001b[1;32m    860\u001b[0m     ]\n\u001b[1;32m    861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'John'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/machine_learning_dika/Pertemuan3/Data_Preprocessing_Tools.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/machine_learning_dika/Pertemuan3/Data_Preprocessing_Tools.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/machine_learning_dika/Pertemuan3/Data_Preprocessing_Tools.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m ct \u001b[39m=\u001b[39m ColumnTransformer(transformers\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m'\u001b[39m, OneHotEncoder(), [\u001b[39m0\u001b[39m])], remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/machine_learning_dika/Pertemuan3/Data_Preprocessing_Tools.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(ct\u001b[39m.\u001b[39;49mfit_transform(X))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py:778\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    776\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record_output_indices(Xs)\n\u001b[0;32m--> 778\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hstack(\u001b[39mlist\u001b[39;49m(Xs))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py:862\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[0;34m(self, Xs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         converted_Xs \u001b[39m=\u001b[39m [\n\u001b[1;32m    858\u001b[0m             check_array(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    859\u001b[0m             \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m Xs\n\u001b[1;32m    860\u001b[0m         ]\n\u001b[1;32m    861\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 862\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    863\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFor a sparse output, all columns should \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    864\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbe a numeric or convertible to a numeric.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    867\u001b[0m     \u001b[39mreturn\u001b[39;00m sparse\u001b[39m.\u001b[39mhstack(converted_Xs)\u001b[39m.\u001b[39mtocsr()\n\u001b[1;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: For a sparse output, all columns should be a numeric or convertible to a numeric."
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
